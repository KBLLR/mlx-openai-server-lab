# Smart Campus Integration - MLX OpenAI Server Configuration
# Copy this file to .env and customize for your environment

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================

# Path to MLX model (local path or HuggingFace model ID)
MODEL_PATH=mlx-community/qwen2.5-7b-instruct-4bit

# Model type: lm (text), multimodal, embeddings, whisper, image-generation, image-edit
MODEL_TYPE=lm

# Maximum context length (tokens)
# Adjust based on your use case:
# - 4096: Short conversations, lower memory
# - 8192: Balanced (recommended for Smart Campus)
# - 16384+: Long documents, higher memory usage
CONTEXT_LENGTH=8192

# ============================================================================
# SERVER CONFIGURATION
# ============================================================================

# Server host (use 127.0.0.1 for localhost-only, 0.0.0.0 for network access)
# IMPORTANT: For security, use 127.0.0.1 unless you need network access
SERVER_HOST=127.0.0.1

# Server port
SERVER_PORT=8000

# Maximum concurrent requests
MAX_CONCURRENCY=1

# Request timeout (seconds)
QUEUE_TIMEOUT=300

# Maximum queue size
QUEUE_SIZE=100

# ============================================================================
# TOOL CALLING CONFIGURATION
# ============================================================================

# Enable automatic tool choice (required for Smart Campus classroom tools)
ENABLE_AUTO_TOOL_CHOICE=true

# Tool call parser: qwen3, glm4_moe, qwen3_moe, qwen3_next, qwen3_vl, harmony, minimax
# Choose based on your model:
# - qwen3: For Qwen 2.5 models (recommended)
# - harmony: For GPT-OSS models
TOOL_CALL_PARSER=qwen3

# Reasoning parser (optional, same options as tool_call_parser)
# REASONING_PARSER=qwen3

# ============================================================================
# PERFORMANCE CONFIGURATION
# ============================================================================

# Enable KV cache warmup (reduces first-token latency)
# Recommended: true for production, false for debugging
MLX_WARMUP=true

# Trust remote code (only enable for models that require custom code)
# IMPORTANT: Security risk - only enable if you trust the model source
TRUST_REMOTE_CODE=false

# ============================================================================
# CORS CONFIGURATION (Smart Campus Frontend)
# ============================================================================

# Smart Campus frontend URL (for CORS)
CAMPUS_FRONTEND_URL=http://localhost:5173

# Additional allowed origins (comma-separated)
# Example: ALLOWED_ORIGINS=http://localhost:3000,http://localhost:4173
# ALLOWED_ORIGINS=

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (default: logs/app.log)
# LOG_FILE=logs/campus-mlx.log

# Disable file logging (console only)
# NO_LOG_FILE=false

# ============================================================================
# SMART CAMPUS SPECIFIC SETTINGS
# ============================================================================

# These are used by Smart Campus, not mlx-openai-server
# Include them here for convenience

# MLX Server URL (used by Smart Campus API)
# MLX_SERVER_URL=http://localhost:8000

# Enable local AI in Smart Campus
# ENABLE_LOCAL_AI=true

# Enable cloud fallback if mlx-server is unavailable
# ENABLE_CLOUD_FALLBACK=false

# ============================================================================
# ADVANCED SETTINGS (Optional)
# ============================================================================

# Disable auto-resize for Vision Language Models
# DISABLE_AUTO_RESIZE=false

# Quantization level for image generation models (4, 8, 16)
# QUANTIZE=8

# Config name for Flux image models
# CONFIG_NAME=flux-schnell

# LoRA paths (comma-separated, for image generation)
# LORA_PATHS=/path/to/lora1.safetensors,/path/to/lora2.safetensors
# LORA_SCALES=0.8,0.6
